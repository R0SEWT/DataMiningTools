{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4af3eef",
   "metadata": {},
   "source": [
    "# PRÁCTICA GUIADA 02\n",
    "\n",
    "---\n",
    "**Curso:** Data Mining Tools  \n",
    "**Semestre:** 2025-2  \n",
    "**Docente:** Carlos Fernando Montoya Cubas  \n",
    "**Grupo:** 08  \n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## ALUMNOS\n",
    "- Mildred Micaela Marchan Quispe  \n",
    "- Rody Sebastian Vilchez Marin  \n",
    "- Rosa Maria Rodríguez Valencia\n",
    "\n",
    "## Instrucciones:  \n",
    "\n",
    "Dado el dataset de fraude crediticio disponible en:   \n",
    "https://www.kaggle.com/datasets/mishra5001/credit-card/data  \n",
    "1. Realizar el preprocesamiento de variables y examinar las relaciones entre los \n",
    "datos.  \n",
    " \n",
    "2. Realizar el escalamiento multidimensional de los datos y realizar la \n",
    "interpretación correspondiente.  \n",
    " \n",
    "3. Crear una clase en python que reciba como parámetro el dataset y los  \n",
    "transformadores correspondientes y pueda realizar el preprocesamiento de las \n",
    "variables. La clase debe interpretar la función fit que calibra los  \n",
    "transformadores y la función transform que realiza la transformación  \n",
    "propiamente dicha. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3567e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib seaborn scikit-learn wordcloud -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# paquete que implementa varios métodos de codificación de variables categóricas\n",
    "!pip install category_encoders kaggle -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18264fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Cargando las bibliotecas\n",
    "# importa  pandas\n",
    "import pandas as pd\n",
    "\n",
    "# gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Escalonamento multidmensional\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "# transformacion de atributos\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# cálculo de distancias\n",
    "from scipy.spatial.distance import pdist, squareform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8726b7e6",
   "metadata": {},
   "source": [
    "\n",
    "## Base de datos\n",
    "\n",
    "**Credit Card Fraud Detection**\n",
    "\n",
    "Este dataset busca obtener insights sobre clientes que incumplen pagos de tarjetas de crédito, usando atributos como Income_Total, AMT_APPLICATION, AMT_CREDIT y más de 120 variables.\n",
    "\n",
    "Incluye también el Previous Application Data Set, que permite analizar patrones y variaciones considerando el historial crediticio.\n",
    "\n",
    "Fue tomado como parte de una asignación académica, aplicando EDA para identificar tendencias y riesgos de incumplimiento. [aqui](https://www.kaggle.com/datasets/mishra5001/credit-card/data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ce0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!kaggle datasets download -d mishra5001/credit-card # setear kaggle api\n",
    "\n",
    "!mkdir -p data\n",
    "!unzip -o credit-card.zip -d data # comprimir en data\n",
    "!rm credit-card.zip # borrar zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb129ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "APP = pd.read_csv('data/application_data.csv')\n",
    "print(APP.shape)\n",
    "APP.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PREVIOUS = pd.read_csv('data/previous_application.csv')\n",
    "print(PREVIOUS.shape)\n",
    "PREVIOUS.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = pd.read_csv('data/columns_description.csv',sep=\",\", encoding='cp1252', index_col=0)\n",
    "print(COLUMNS.shape)\n",
    "COLUMNS.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dcdf84",
   "metadata": {},
   "source": [
    "\n",
    "### Seleccion del dataset\n",
    "\n",
    "Los datos de la aplicación principal se encuentran en el archivo `application_data.csv`, que contiene 122 columnas y 307511 filas. El conjunto de datos de aplicaciones previas está en `previous_application.csv`, con 37 columnas y 1670214 filas. La descripción de las columnas está en `columns_description.csv`.\n",
    "\n",
    "Exploraremos `columns_description.csv` para entender las variables, y luego escogeremos un conjunto de datos para análisis y preprocesamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21466e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "COLUMNS[\"Table\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded12d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COLUMNS[COLUMNS['Table'] == 'application_data'].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COLUMNS[COLUMNS['Table'] == 'previous_application.csv'].describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d2f115",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Tratamiento`Special` segun tipo de tabla`Table`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63fda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs = COLUMNS['Table'].unique()\n",
    "\n",
    "for df in dfs:\n",
    "    prev_app = COLUMNS[COLUMNS['Table'] == df]\n",
    "    freq = prev_app['Special'].value_counts(normalize=True, dropna=False) * 100\n",
    "    freq = freq.round(2)\n",
    "    print(df, end=\"\\n\\n\")\n",
    "    \n",
    "    print(freq)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a538413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wordclod por tratamiento `Special` por tipo de tabla`Table`\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "text_prev = ' '.join(COLUMNS[COLUMNS['Table'] == 'previous_application.csv']['Description'].dropna().values)\n",
    "text_app = ' '.join(COLUMNS[COLUMNS['Table'] == 'application_data']['Description'].dropna().values)\n",
    "\n",
    "\n",
    "wordcloud_prev = WordCloud(width=800, height=400, background_color='white').generate(text_prev)\n",
    "wordcloud_app = WordCloud(width=800, height=400, background_color='white').generate(text_app)\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(wordcloud_prev, interpolation='bilinear')\n",
    "plt.title('Previous Application Description')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(wordcloud_app, interpolation='bilinear')\n",
    "plt.title('Application Data Description')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a913ec",
   "metadata": {},
   "source": [
    "\n",
    "Dado que el proposito de la leccion es limpiar datos, se opta por trabajar con el dataset `previoys_application.csv` que contiene los datos crudos. Este conjunto es el mas adecuado para aplicar y practicar tecnicas de preprocesamiento y analisis exploratorio.\n",
    "\n",
    "El dataset de `application_data.csv` se podra llegar a usar como control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41ae840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# descripcion de los atributos numéricos\n",
    "PREVIOUS.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ca8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# descripcion de los atributos categóricos\n",
    "PREVIOUS.describe(include = 'object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIOUS.isnull().mean().sort_values(ascending=False).__round__(3).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b49fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(PREVIOUS.isnull(), cbar=False) # demora 2 dias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e04d7d4",
   "metadata": {},
   "source": [
    "Vamos a analizar los atributos categóricos, para clasificarlos entre discreto y ordinal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd280e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for column_name in PREVIOUS.select_dtypes(include=[\"object_\"]):\n",
    "  print(column_name, \"->\", PREVIOUS[column_name].unique())\n",
    "  print()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb005d",
   "metadata": {},
   "source": [
    "Vamos a separar los atributos nominales y ordinales para hacer una transformacion a numérica, para calcular distancias:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce4654",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_cols = ['NAME_CONTRACT_TYPE', 'NAME_CASH_LOAN_PURPOSE', \n",
    "                'NAME_PAYMENT_TYPE', 'CODE_REJECT_REASON', 'NAME_TYPE_SUITE', \n",
    "                'NAME_CLIENT_TYPE', 'NAME_GOODS_CATEGORY', 'NAME_PORTFOLIO',\n",
    "                'NAME_PRODUCT_TYPE', 'CHANNEL_TYPE','NAME_SELLER_INDUSTRY',\n",
    "                'PRODUCT_COMBINATION', 'FLAG_LAST_APPL_PER_CONTRACT',  'NAME_CONTRACT_STATUS'\n",
    "                ]\n",
    "\n",
    "ordinal_cols = ['WEEKDAY_APPR_PROCESS_START', \n",
    "               'NAME_YIELD_GROUP'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f00d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = [\n",
    "    {'col': 'WEEKDAY_APPR_PROCESS_START',\n",
    "     'mapping': {\n",
    "         'MONDAY': 0,\n",
    "         'TUESDAY': 1,\n",
    "         'WEDNESDAY': 2,\n",
    "         'THURSDAY': 3,\n",
    "         'FRIDAY': 4,\n",
    "         'SATURDAY': 5,\n",
    "         'SUNDAY': 6\n",
    "     }},\n",
    "    \n",
    "    {'col': 'NAME_YIELD_GROUP',\n",
    "     'mapping': {\n",
    "         'low_action': 0,\n",
    "         'low_normal': 1,\n",
    "         'middle': 2,\n",
    "         'high': 3,\n",
    "         'XNA': -1\n",
    "     }}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac593f1e",
   "metadata": {},
   "source": [
    "\n",
    "Precisamos explicitar a ordem para os atributos ordinais, uma vez que a ordem em que eles aparacem pode ser diferente da ordem desejada:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1b02a",
   "metadata": {},
   "source": [
    "Ahora vamos a crear los objetos que hacen la transformación. Para los atributos nominales, utilizaremos la codificación 1 de m (One-Hot-Encoding). En cuanto a los atributos categóricos, usemos el orden creado anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotenc = OneHotEncoder(cols = nominal_cols)\n",
    "ordinalenc = OrdinalEncoder(cols = ordinal_cols, mapping = mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f943704",
   "metadata": {},
   "source": [
    "Inicialmente, transformamos os atributos nominales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4539dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIOUS_1 = onehotenc.fit_transform(PREVIOUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41142196",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIOUS_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dce03b",
   "metadata": {},
   "source": [
    "Ahora aplicamos la transformacion de los ordinales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIOUS_2 = ordinalenc.fit_transform(PREVIOUS_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIOUS_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85600d",
   "metadata": {},
   "source": [
    "Finalmente, un tratamento de valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce6a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIOUS_3 = PREVIOUS_2.fillna(PREVIOUS_2.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5453ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIOUS_3.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cac415",
   "metadata": {},
   "source": [
    "Para acelerar los cálculos, tomemos una muestra aleatoria de esta versión procesada. Además, para que un atributo no tenga mayor importancia que los demás, cambiemos la escala para que todos tengan valores entre 0 y 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample = PREVIOUS_3.sample(1000)\n",
    "print(sample.columns.to_list())\n",
    "\n",
    "max_amt_credit = max(sample.AMT_CREDIT)\n",
    "max_rate_down_payment = max(sample.RATE_DOWN_PAYMENT)\n",
    "\n",
    "# normalización Min-Max\n",
    "sample = sample.loc[:, sample.nunique() > 1]\n",
    "sample = (sample - sample.min()) / (sample.max() - sample.min()) # evita columnas constantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e442f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c006997",
   "metadata": {},
   "source": [
    "Ahora, vamos a calcular la matriz de distancias\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6406ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = squareform(pdist(sample,'euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e1ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7169d9",
   "metadata": {},
   "source": [
    "Ahora vamos a crear un objeto Método que calcule el escalado multidimensional. Como ya hemos calculado la matriz de disimilitud, pasamos el argumento 'precalculado' (si no lo hacemos, el método calcula internamente la matriz de distancia euclidiana). La implementación utiliza un enfoque iterativo para minimizar la función de estrés. La opción detallada es para que sigamos la evolución de esta función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f6365",
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = MDS(dissimilarity='precomputed',verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822f15a",
   "metadata": {},
   "source": [
    "Una vez que se ha creado el objeto, podemos aplicarlo a la matriz de distancia, que calculamos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083943c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = mds.fit_transform(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = squareform(pdist(sample,'cityblock'))\n",
    "transformed_city = mds.fit_transform(dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8150035",
   "metadata": {},
   "source": [
    "Para visualizar esta transformación, podemos hacer un diagrama de dispersión. Para ayudar a la interpretación, utilizaremos un código de colores basado en la edad de los individuos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a0df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "scatter1 = ax1.scatter(transformed[:,0], transformed[:,1], \n",
    "                       c=sample.AMT_CREDIT * max_amt_credit, cmap=\"viridis\")\n",
    "legend1 = ax1.legend(*scatter1.legend_elements(), title=\"Amount Credit (Euclidean)\")\n",
    "ax1.add_artist(legend1)\n",
    "\n",
    "scatter2 = ax2.scatter(transformed_city[:,0], transformed_city[:,1], \n",
    "                       c=sample.AMT_CREDIT * max_amt_credit, cmap=\"viridis\")\n",
    "legend2 = ax2.legend(*scatter2.legend_elements(), title=\"Amount Credit (Cityblock)\")\n",
    "ax2.add_artist(legend2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb807fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "scatter1 = ax1.scatter(transformed[:,0], transformed[:,1], \n",
    "                       c=sample.NAME_YIELD_GROUP , cmap=\"viridis\")\n",
    "legend1 = ax1.legend(*scatter1.legend_elements(), title=\"Name Yield Group (Euclidean)\")\n",
    "ax1.add_artist(legend1)\n",
    "\n",
    "scatter2 = ax2.scatter(transformed_city[:,0], transformed_city[:,1], \n",
    "                       c=sample.NAME_YIELD_GROUP, cmap=\"viridis\")\n",
    "legend2 = ax2.legend(*scatter2.legend_elements(), title=\"Name Yield Group (Cityblock)\")\n",
    "ax2.add_artist(legend2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "scatter1 = ax1.scatter(transformed[:,0], transformed[:,1], \n",
    "                       c=sample.NAME_CONTRACT_TYPE_1 , cmap=\"viridis\")\n",
    "legend1 = ax1.legend(*scatter1.legend_elements(), title=\"Name Contract Type (Euclidean)\")\n",
    "ax1.add_artist(legend1)\n",
    "\n",
    "scatter2 = ax2.scatter(transformed_city[:,0], transformed_city[:,1], \n",
    "                       c=sample.NAME_CONTRACT_TYPE_1, cmap=\"viridis\")\n",
    "legend2 = ax2.legend(*scatter2.legend_elements(), title=\"Name Contract Type  (Cityblock)\")\n",
    "ax2.add_artist(legend2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc59df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "scatter1 = ax1.scatter(transformed[:,0], transformed[:,1], \n",
    "                       c=sample.RATE_DOWN_PAYMENT * max_rate_down_payment, cmap=\"viridis\")\n",
    "legend1 = ax1.legend(*scatter1.legend_elements(), title=\"Rate Down Payment (Euclidean)\")\n",
    "ax1.add_artist(legend1)\n",
    "\n",
    "scatter2 = ax2.scatter(transformed_city[:,0], transformed_city[:,1], \n",
    "                       c=sample.RATE_DOWN_PAYMENT * max_rate_down_payment, cmap=\"viridis\")\n",
    "legend2 = ax2.legend(*scatter2.legend_elements(), title=\"Rate Down Payment (Cityblock)\")\n",
    "ax2.add_artist(legend2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865bc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "scatter1 = ax1.scatter(transformed[:,0], transformed[:,1], \n",
    "                       c=sample.NAME_CLIENT_TYPE_2 , cmap=\"viridis\")\n",
    "legend1 = ax1.legend(*scatter1.legend_elements(), title=\"Name Client Type 2(New) (Euclidean)\")\n",
    "ax1.add_artist(legend1)\n",
    "\n",
    "scatter2 = ax2.scatter(transformed_city[:,0], transformed_city[:,1], \n",
    "                       c=sample.NAME_CLIENT_TYPE_2, cmap=\"viridis\")\n",
    "legend2 = ax2.legend(*scatter2.legend_elements(), title=\"Name Client Type 2 (New) (Cityblock)\")\n",
    "ax2.add_artist(legend2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f934c3",
   "metadata": {},
   "source": [
    "## Asociaciones entre variables\n",
    "\n",
    "Ahora investiguemos algunas asociaciones entre variables en esta base (usando la base original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c034f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x=PREVIOUS['NAME_CONTRACT_TYPE'], y=PREVIOUS['AMT_CREDIT'])\n",
    "plt.title('Distribución de AMT_CREDIT según NAME_CONTRACT_TYPE')\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa0fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Asociación entre dos variables categóricas\n",
    "pd.crosstab(PREVIOUS['NAME_CONTRACT_TYPE'], PREVIOUS['NAME_CLIENT_TYPE'], margins=True, normalize='index').round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=PREVIOUS_3['AMT_CREDIT'], y=PREVIOUS_3['RATE_DOWN_PAYMENT'])\n",
    "plt.title('Relación entre AMT_CREDIT y RATE_DOWN_PAYMENT')\n",
    "plt.xlabel('AMT_CREDIT')\n",
    "plt.ylabel('RATE_DOWN_PAYMENT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd37ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 1. Preprocesamiento y exploración de relaciones\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import MDS\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ea533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = PREVIOUS.copy()  \n",
    "\n",
    "df_num = df.select_dtypes(include=[np.number])\n",
    "df_cat = df.select_dtypes(include=['object', 'category'])\n",
    "\n",
    "df_num = df_num.fillna(df_num.median())\n",
    "df_cat = df_cat.fillna('Desconocido')\n",
    "\n",
    "# Codificación de variables categóricas\n",
    "onehot = OneHotEncoder(cols=df_cat.columns, use_cat_names=True)\n",
    "df_cat_enc = onehot.fit_transform(df_cat)\n",
    "\n",
    "# Unir datos preprocesados\n",
    "df_proc = pd.concat([df_num, df_cat_enc], axis=1)\n",
    "\n",
    "# Análisis exploratorio: correlación y distribuciones\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.set(rc={'figure.figsize':(15,15)})\n",
    "corr = df_num.corr()\n",
    "sns.heatmap(corr, cmap=cmap, vmax=1, vmin=-1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.title('Matriz de correlación de variables numéricas')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Distribuciones\n",
    "# for col in df_num.columns:\n",
    "#     plt.figure()\n",
    "#     sns.histplot(df_num[col], kde=True)\n",
    "#     plt.title(f'Distribución de {col}')\n",
    "#     plt.show()\n",
    "\n",
    "# 2. Escalamiento multidimensional (MDS)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_proc)\n",
    "mds = MDS(n_components=2, random_state=42)\n",
    "mds_coords = mds.fit_transform(df_scaled)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(mds_coords[:,0], mds_coords[:,1], alpha=0.7)\n",
    "plt.title('Escalamiento Multidimensional (MDS)')\n",
    "plt.xlabel('Componente 1')\n",
    "plt.ylabel('Componente 2')\n",
    "plt.show()\n",
    "\n",
    "# 3. Clase de preprocesamiento generalizada\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class GeneralPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_strategy='median', cat_strategy='Desconocido', encoder=None, scaler=None):\n",
    "        self.num_strategy = num_strategy\n",
    "        self.cat_strategy = cat_strategy\n",
    "        self.encoder = encoder if encoder is not None else OneHotEncoder(use_cat_names=True)\n",
    "        self.scaler = scaler if scaler is not None else StandardScaler()\n",
    "        self.num_cols = None\n",
    "        self.cat_cols = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "        self.cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "        self.num_medians = X[self.num_cols].median()\n",
    "        self.encoder.fit(X[self.cat_cols].fillna(self.cat_strategy))\n",
    "        self.scaler.fit(pd.concat([\n",
    "            X[self.num_cols].fillna(self.num_strategy),\n",
    "            self.encoder.transform(X[self.cat_cols].fillna(self.cat_strategy))\n",
    "        ], axis=1))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_num = X[self.num_cols].fillna(self.num_strategy)\n",
    "        X_cat = X[self.cat_cols].fillna(self.cat_strategy)\n",
    "        X_cat_enc = self.encoder.transform(X_cat)\n",
    "        X_proc = pd.concat([X_num, X_cat_enc], axis=1)\n",
    "        X_scaled = self.scaler.transform(X_proc)\n",
    "        return X_scaled\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780e0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = GeneralPreprocessor()\n",
    "preproc.fit(df)\n",
    "datos_transformados = preproc.transform(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMiningTools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
